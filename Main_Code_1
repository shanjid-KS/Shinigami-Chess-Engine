#!/usr/bin/env python3
"""
Shinigami V.1.16.9 - Professional Chess Engine with Full Tree Parallelization and Advanced NNUE
Author: Tonmoy-KS
License: MIT License (credit @Tonmoy-KS, do not claim as own)
"""

import chess
import chess.syzygy
import chess.polyglot
import random
import time
import logging
import multiprocessing as mp
from multiprocessing import Manager, Pool
from collections import defaultdict
import numpy as np
import os
from scipy.sparse import csr_matrix
import sqlite3
import torch
import torch.nn as nn
import torch.nn.functional as F
import tkinter as tk
import cProfile
import pstats
from typing import List, Dict

# Configure logging statistics
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    filename='shinigami_engine.log'
)

class ShinigamiConfig:
    """Configuration settings for the Shinigami chess engine."""
    ENGINE_NAME = "Shinigami V.1.16.9 - Gen 2 Edition"
    PIECE_VALUES = {
        chess.PAWN: 100,
        chess.KNIGHT: 520,
        chess.BISHOP: 530,
        chess.ROOK: 800,
        chess.QUEEN: 900,  # Queen is less so the Engine can make Powerful sacrifices without being Held back by Piece Values
        # King Value not Omitted due to it not being used in Board Evaluation
    }
    TIME_CONTROLS = {
        'easy': {'base': 5, 'increment': 1},
        'medium': {'base': 15, 'increment': 3},
        'hard': {'base': 30, 'increment': 5},
        'god-of-death': {'base': 60, 'increment': 50},
        'puzzle': {'base': 30, 'increment': 0},
        'masochist': {'base': 7000000, 'increment': 150},
        'dialing-satan-s-number': {'base': 2177430688000000000, 'increment': 1000000},  # Yeah that's 69 Eons
        'the-big-bang': {'base': float('inf'), 'increment': 435475000800000000}  # Infinite time for The Big Bang and the increment time is same as the time since the Big Bang occured
    }
    DEPTHS = {
        'easy': 1,  # Newbie?
        'medium': 6,  # Hardcore Amateur Player
        'hard': 14,  # Strong but not the Strongest
        'god-of-death': 24,  # The Best
        'puzzle': 4,
        'masochist': 40,  # you like Pain eh?
        'dialing-satan-s-number': 85000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000,  # it's just Experimental do NOT enable
        'the-big-bang': float('inf')  # Infinite depth
    }
    NNUE_FILE = os.getenv('SHINIGAMI_NNUE_FILE', 'nnue_weights.bin')
    SYZYGY_PATH = os.getenv('SHINIGAMI_SYZYGY_PATH', './tablebases')
    USE_NNUE = True  # Enabled by Default but disable it if you don't have Python-Torch Installed
    NUM_PROCESSES = max(1, mp.cpu_count() // 2)
    PIECE_SQUARE_TABLES = {
        chess.PAWN: [
            0, 0, 0, 0, 0, 0, 0, 0,
            50, 50, 50, 50, 50, 50, 50, 50,
            10, 10, 20, 30, 30, 20, 10, 10,
            5, 5, 10, 25, 25, 10, 5, 5,
            0, 0, 0, 20, 20, 0, 0, 0,
            5, -5, -10, 0, 0, -10, -5, 5,
            5, 10, 10, -20, -20, 10, 10, 5,
            0, 0, 0, 0, 0, 0, 0, 0
        ],
        chess.KNIGHT: [
            -50, -40, -30, -30, -30, -30, -40, -50,
            -40, -20, 0, 0, 0, 0, -20, -40,
            -30, 0, 10, 15, 15, 10, 0, -30,
            -30, 5, 15, 20, 20, 15, 5, -30,
            -30, 0, 15, 20, 20, 15, 0, -30,
            -30, 5, 10, 15, 15, 10, 5, -30,
            -40, -20, 0, 5, 5, 0, -20, -40,
            -50, -40, -30, -30, -30, -30, -40, -50
        ],
        chess.BISHOP: [
            -20, -10, -10, -10, -10, -10, -10, -20,
            -10, 0, 0, 0, 0, 0, 0, -10,
            -10, 0, 5, 10, 10, 5, 0, -10,
            -10, 5, 5, 10, 10, 5, 5, -10,
            -10, 0, 10, 10, 10, 10, 0, -10,
            -10, 10, 10, 0, 0, 10, 10, -10,
            -10, 5, 0, 0, 0, 0, 5, -10,
            -20, -10, -10, -10, -10, -10, -10, -20
        ],
        chess.ROOK: [
            0, 0, 0, 0, 0, 0, 0, 0,
            5, 10, 10, 10, 10, 10, 10, 5,
            0, 0, 0, 0, 0, 0, 0, 0,
            -5, 0, 0, 0, 0, 0, 0, -5,
            -5, 0, 0, 0, 0, 0, 0, -5,
            -5, 0, 0, 0, 0, 0, 0, -5,
            -5, 0, 0, 0, 0, 0, 0, -5,
            0, 0, 0, 5, 5, 0, 0, 0
        ],
        chess.QUEEN: [
            -20, -10, -10, -5, -5, -10, -10, -20,
            -10, 0, 0, 0, 0, 0, 0, -10,
            -10, 0, 5, 5, 5, 5, 0, -10,
            -5, 0, 5, 5, 5, 5, 0, -5,
            0, 0, 5, 5, 5, 5, 0, -5,
            -10, 5, 5, 5, 5, 5, 0, -10,
            -10, 0, 5, 0, 0, 0, 0, -10,
            -20, -10, -10, -5, -5, -10, -10, -20
        ],
        chess.KING: [
            -30, -40, -40, -50, -50, -40, -40, -30,
            -30, -40, -40, -50, -50, -40, -40, -30,
            -30, -40, -40, -50, -50, -40, -40, -30,
            -30, -40, -40, -50, -50, -40, -40, -30,
            -20, -30, -30, -40, -40, -30, -30, -20,
            -10, -20, -20, -20, -20, -20, -20, -10,
            20, 20, 0, 0, 0, 0, 20, 20,
            20, 30, 10, 5, 5, 10, 30, 20
        ]
    }
    TRASH_TALK = {
        "move": [
            "Keep up, or I'll Ctrl+Alt+Del your whole board.",
            "Your moves are so predictable. I'm playing blindfolded.",
            "I'm two moves from reaping your soul. Hurry up."
        ],
        "check": [
            "Check! Your king's trembling already.",
            "Check! Time to panic or pray—your choice.",
            "Check! I'm carving your board like a Halloween pumpkin."
        ],
        "capture": [
            "Yoink! That piece is mine now.",
            "Captured. You're running out of toys.",
            "Snagged your piece. Should've seen that fork coming."
        ],
        "win": [
            "GG, I just Alt+F4'd your entire existence!",
            "Checkmate! Your rating's in the shadow realm now.",
            "Game over. I just reaped your soul. GG."
        ],
        "draw": [
            "Draw? You survived... barely. I'm disappointed.",
            "Stalemate? That's the saddest ending possible.",
            "Draw? I'll haunt your next game, don't worry."
        ],
        "loss": [
            "You got plot armor or what? White wins... for now.",
            "White wins. Enjoy it while it lasts, mortal.",
            "You won? Must've been my coffee break."
        ],
        "invalid": [
            "That's not a move, it's a cry for help!",
            "Illegal move! Do you even chess, bro?",
            "Invalid move! Did you borrow that from a 1000-rated game?",
            "I can't differentiate if you're playing wrong or existing the wrong way."
        ],
        "opening": [
            "You brought the London System? Weak.",
            "King's Pawn Opening? How original.",
            "Sicilian? Bold, but I'm still gonna shred you.",
            "You still follow theory? I am the Einstein of Chess."
        ],
        "time_pressure": [
            "Tick-tock, your clock's screaming for mercy.",
            "Time's burning, just like your position.",
            "Low on time? I'll finish this before you blink."
        ],
        "the_big_bang": [
            "The Big Bang? I'd rather calculate the universe's expansion than that depth!",
            "Infinite depth? The universe would collapse before I make a move. Pick something sane!",
            "The Big Bang mode? Nope, I'm not unraveling the fabric of reality today!",
            "∞ depth? I can't even handle that kind of cosmic chaos. Choose again!",
            "The Big Bang? I'd need a billion years and a black hole to compute that. Try again!",
            "You really want to see the heat death of the Universe? Call Entropy-Kun.",
            "Infinite depth? I'd be stuck until the heat death of the universe. Nope."
        ]
    }

class NNUE(nn.Module):
    """Neural Network for position evaluation using HalfKAv2 feature set."""
    def __init__(self, input_size=98304, hidden_size=256):  
        super(NNUE, self).__init__()
        self.input_layer = nn.Linear(input_size, hidden_size)
        self.hidden_layer = nn.Linear(hidden_size, hidden_size)
        self.output_layer = nn.Linear(hidden_size, 1)
        self.crelu = lambda x: torch.clamp(x, 0, 1)  # Clipped ReLU for NNUE

    def forward(self, x):
        x = self.crelu(self.input_layer(x))
        x = self.crelu(self.hidden_layer(x))
        return self.output_layer(x)

class PolicyNetwork(nn.Module):
    """Neural network for suggesting move probabilities using a CNN."""
    def __init__(self, input_channels=12, hidden_size=256, output_size=4672):
        super(PolicyNetwork, self).__init__()
        self.conv1 = nn.Conv2d(input_channels, 64, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)
        self.fc1 = nn.Linear(128 * 8 * 8, hidden_size)
        self.fc2 = nn.Linear(hidden_size, output_size)
        self.relu = nn.ReLU()
        self.softmax = nn.Softmax(dim=-1)
        # Mapping of moves to indices for output layer
        self.move_to_index = {}
        self.index_to_move = {}
        self._build_move_mapping()

    def _build_move_mapping(self):
        """Create a mapping of UCI moves to indices."""
        board = chess.Board()
        idx = 0
        for move in board.legal_moves:
            uci = move.uci()
            if uci not in self.move_to_index:
                self.move_to_index[uci] = idx
                self.index_to_move[idx] = uci
                idx += 1
        for from_square in range(64):
            for to_square in range(64):
                for promotion in [None, chess.QUEEN, chess.ROOK, chess.BISHOP, chess.KNIGHT]:
                    move = chess.Move(from_square, to_square, promotion)
                    uci = move.uci()
                    if uci not in self.move_to_index and idx < 4672:
                        self.move_to_index[uci] = idx
                        self.index_to_move[idx] = uci
                        idx += 1

    def forward(self, x):
        """Forward pass: board state (12x8x8) -> move probabilities."""
        x = self.relu(self.conv1(x))
        x = self.relu(self.conv2(x))
        x = x.view(-1, 128 * 8 * 8)
        x = self.relu(self.fc1(x))
        x = self.fc2(x)
        return self.softmax(x)

    def get_move_probabilities(self, board: chess.Board, legal_moves: List[chess.Move]) -> Dict[chess.Move, float]:
        """Generate move probabilities for legal moves."""
        features = self.encode_board(board)
        with torch.no_grad():
            probs = self.forward(torch.tensor(features, dtype=torch.float32).unsqueeze(0))
        move_probs = {}
        for move in legal_moves:
            uci = move.uci()
            idx = self.move_to_index.get(uci, 0)
            move_probs[move] = probs[0, idx].item()
        total = sum(move_probs.values())
        if total > 0:
            move_probs = {move: prob / total for move, prob in move_probs.items()}
        return move_probs

    @staticmethod
    def encode_board(board: chess.Board) -> np.ndarray:
        """Encode board state into 12x8x8 planes (6 piece types x 2 colors)."""
        planes = np.zeros((12, 8, 8), dtype=np.float32)
        for square in chess.SQUARES:
            piece = board.piece_at(square)
            if piece:
                piece_idx = piece.piece_type - 1 + (6 if piece.color == chess.BLACK else 0)
                rank = 7 - chess.square_rank(square)
                file = chess.square_file(square)
                planes[piece_idx, rank, file] = 1.0
        return planes

    def train(self, dataset: List[tuple], epochs: int = 10, batch_size: int = 32):
        """Train the policy network on a dataset of (FEN, move) pairs."""
        optimizer = torch.optim.Adam(self.parameters(), lr=0.001)
        criterion = nn.CrossEntropyLoss()
        for epoch in range(epochs):
            np.random.shuffle(dataset)
            total_loss = 0
            for i in range(0, len(dataset), batch_size):
                batch = dataset[i:i + batch_size]
                inputs = []
                targets = []
                for fen, move_uci in batch:
                    board = chess.Board(fen)
                    inputs.append(self.encode_board(board))
                    targets.append(self.move_to_index.get(move_uci, 0))
                inputs = torch.tensor(np.array(inputs), dtype=torch.float32)
                targets = torch.tensor(targets, dtype=torch.long)
                optimizer.zero_grad()
                outputs = self.forward(inputs)
                loss = criterion(outputs, targets)
                loss.backward()
                optimizer.step()
                total_loss += loss.item()
            logging.info(f"Policy network training epoch {epoch + 1}/{epochs}, loss: {total_loss / (len(dataset) // batch_size)}")
        torch.save(self.state_dict(), 'policy_network.pth')

class AdvancedNNUEEvaluator:
    """Handles advanced NNUE evaluation with HalfKAv2 feature set."""
    def __init__(self, nnue_file: str):
        self.input_size = 98304  # 64 * 64 * 12 * 2 (white + black perspectives)
        self.model = NNUE(input_size=self.input_size)
        try:
            self.model.load_state_dict(torch.load(nnue_file))
            logging.info("Loaded NNUE weights")
        except Exception as e:
            logging.warning(f"Failed to load NNUE weights: {e}. Falling back to traditional evaluation.")
            self.model = None

    def evaluate(self, board: chess.Board) -> int:
        """Evaluate board using NNUE or fallback to traditional evaluation."""
        if self.model is None:
            return 0
        features = self.encode_halfkav2(board)
        with torch.no_grad():
            score = self.model(torch.tensor(features, dtype=torch.float32)).item()
        return int(score * 100)

    def encode_halfkav2(self, board: chess.Board) -> np.ndarray:
        """Encode board state into HalfKAv2 features (full implementation)."""
        # [Full HalfKAv2 Implementation]
        # Encodes piece positions relative to both kings (white and black perspectives).
        # Features: 64 (king positions) x 64 (squares) x 12 (piece types) x 2 (perspectives).
        # Uses sparse matrix for efficiency due to low feature activation.
        feature_size = 64 * 64 * 12  # Features per perspective
        indices = []
        data = []
        white_king = board.king(chess.WHITE)
        black_king = board.king(chess.BLACK)
        # White's perspective
        if white_king is not None:
            for square in chess.SQUARES:
                piece = board.piece_at(square)
                if piece and piece.piece_type != chess.KING:  # Exclude kings
                    piece_idx = piece.piece_type - 1 + (6 if piece.color == chess.BLACK else 0)
                    feature_idx = white_king * 64 * 12 + square * 12 + piece_idx
                    indices.append(feature_idx)
                    data.append(1.0)
        # Black's perspective (mirrored board)
        if black_king is not None:
            for square in chess.SQUARES:
                piece = board.piece_at(square)
                if piece and piece.piece_type != chess.KING:
                    piece_idx = piece.piece_type - 1 + (6 if piece.color == chess.BLACK else 0)
                    feature_idx = feature_size + chess.square_mirror(black_king) * 64 * 12 + chess.square_mirror(square) * 12 + piece_idx
                    indices.append(feature_idx)
                    data.append(1.0)
        # Create sparse matrix
        features = csr_matrix((data, (np.zeros(len(indices), dtype=np.int64), indices)),
                             shape=(1, self.input_size), dtype=np.float32)
        return features.toarray().flatten()

class TrainingModule:
    """Manages self-play and training for opening book and NNUE weights."""
    def __init__(self):
        self.conn = sqlite3.connect('shinigami_games.db')
        self.conn.execute('''CREATE TABLE IF NOT EXISTS games
                            (id INTEGER PRIMARY KEY, fen TEXT, move TEXT, result TEXT)''')
        self.opening_book = defaultdict(lambda: {'weight': 1.0, 'count': 0, 'wins': 0, 'losses': 0, 'draws': 0})

    def self_play(self, engine, num_games=100):
        """Run self-play games in parallel to generate training data."""
        def play_single_game(game_idx):
            board = chess.Board()
            game_moves = []
            while not board.is_game_over():
                move = engine.get_best_move(board, depth=6, difficulty='medium')
                game_moves.append(move.uci())
                board.push(move)
            result = board.result()
            self.conn.execute("INSERT INTO games (fen, move, result) VALUES (?, ?, ?)",
                             (board.fen(), game_moves[-1], result))
            self.conn.commit()
            self.update_opening_book(board, game_moves, result)
            logging.debug(f"Self-play game {game_idx + 1}/{num_games} completed")
        with mp.Pool(engine.config.NUM_PROCESSES) as pool:
            pool.map(play_single_game, range(num_games))
        logging.info(f"Completed {num_games} self-play games")

    def update_opening_book(self, board: chess.Board, moves: list, result: str):
        """Update opening book with game outcomes, tracking win/loss/draw stats."""
        board.reset()
        weight = 1.0 if result == '1-0' else -1.0 if result == '0-1' else 0.5
        for move in moves[:10]:
            zobrist_hash = chess.polyglot.zobrist_hash(board)
            self.opening_book[zobrist_hash]['weight'] += weight
            self.opening_book[zobrist_hash]['count'] += 1
            if result == '1-0':
                self.opening_book[zobrist_hash]['wins'] += 1
            elif result == '0-1':
                self.opening_book[zobrist_hash]['losses'] += 1
            else:
                self.opening_book[zobrist_hash]['draws'] += 1
            board.push_uci(move)
        total_weight = sum(entry['weight'] for entry in self.opening_book.values())
        if total_weight > 0:
            for key in list(self.opening_book.keys()):
                entry = self.opening_book[key]
                win_rate = entry['wins'] / entry['count'] if entry['count'] > 0 else 0
                if entry['count'] > 20 and win_rate < 0.3:
                    del self.opening_book[key]
                    logging.debug(f"Pruned opening book entry: {key}")

    def learn_from_opponent(self, board: chess.Board, move: chess.Move, result: str):
        """Update opening book based on opponent's moves with strength estimation."""
        zobrist_hash = chess.polyglot.zobrist_hash(board)
        board_copy = board.copy()
        board_copy.push(move)
        eval_before = self.engine.evaluate_position(board) if hasattr(self, 'engine') else 0
        eval_after = self.engine.evaluate_position(board_copy) if hasattr(self, 'engine') else 0
        move_quality = eval_before - eval_after
        opponent_strength = max(0.5, min(1.5, 1.0 - move_quality / 1000))
        weight = (0.8 * opponent_strength) if result in ['1-0', '0-1'] else (0.4 * opponent_strength)
        self.opening_book[zobrist_hash]['weight'] += weight
        self.opening_book[zobrist_hash]['count'] += 1
        if result == '1-0':
            self.opening_book[zobrist_hash]['wins'] += 1
        elif result == '0-1':
            self.opening_book[zobrist_hash]['losses'] += 1
        else:
            self.opening_book[zobrist_hash]['draws'] += 1
        if self.opening_book[zobrist_hash]['count'] > 20:
            win_rate = self.opening_book[zobrist_hash]['wins'] / self.opening_book[zobrist_hash]['count']
            if win_rate < 0.3:
                del self.opening_book[zobrist_hash]
                logging.debug(f"Pruned opponent opening entry: {zobrist_hash}")
        logging.info(f"Learned opponent move {move.uci()}, estimated strength: {opponent_strength}")

    def train_nnue(self, dataset, epochs=10):
        """Train NNUE model on a dataset of (FEN, evaluation) pairs."""
        model = NNUE(input_size=98304)
        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
        criterion = nn.MSELoss()
        for epoch in range(epochs):
            for fen, target_eval in dataset:
                board = chess.Board(fen)
                features = self.engine.nnue.encode_halfkav2(board) if hasattr(self, 'engine') else np.zeros(98304)
                output = model(torch.tensor(features, dtype=torch.float32))
                loss = criterion(output, torch.tensor([target_eval], dtype=torch.float32))
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()
            logging.info(f"Epoch {epoch + 1}/{epochs} completed")
        torch.save(model.state_dict(), ShinigamiConfig.NNUE_FILE)

    def retrain_nnue(self):
        """Retrain NNUE using self-play game data."""
        dataset = []
        for row in self.conn.execute("SELECT fen, result FROM games"):
            fen, result = row
            eval_score = 1.0 if result == '1-0' else -1.0 if result == '0-1' else 0.0
            dataset.append((fen, eval_score))
        if dataset:
            self.train_nnue(dataset)

    def train_policy_network(self, policy_network: PolicyNetwork, epochs: int = 10):
        """Train policy network using self-play game data."""
        dataset = []
        for row in self.conn.execute("SELECT fen, move FROM games"):
            fen, move = row
            dataset.append((fen, move))
        if dataset:
            policy_network.train(dataset, epochs)
            logging.info("Policy network training completed")

    def auto_feature_engineering(self, engine, generations=10, population_size=50):
        """Automated feature engineering using genetic algorithms."""
        # [Full Feature Engineering Implementation]
        try:
            from deap import base, creator, tools, algorithms
        except ImportError:
            logging.error("DEAP library required for feature engineering. Install with: pip install deap")
            return
        self.engine = engine
        creator.create("FitnessMax", base.Fitness, weights=(1.0,))
        creator.create("Individual", list, fitness=creator.FitnessMax)

        def generate_individual():
            piece_values = {piece: value + random.uniform(-50, 50) for piece, value in engine.config.PIECE_VALUES.items()}
            pst = {piece: [v + random.uniform(-10, 10) for v in table] for piece, table in engine.config.PIECE_SQUARE_TABLES.items()}
            individual = list(piece_values.values()) + [v for table in pst.values() for v in table]
            return creator.Individual(individual)

        def evaluate_individual(individual):
            piece_values = {piece: individual[i] for i, piece in enumerate(engine.config.PIECE_VALUES.keys())}
            pst = {}
            idx = len(piece_values)
            for piece in engine.config.PIECE_SQUARE_TABLES:
                pst[piece] = individual[idx:idx+64]
                idx += 64
            original_pv = engine.config.PIECE_VALUES
            original_pst = engine.config.PIECE_SQUARE_TABLES
            engine.config.PIECE_VALUES = piece_values
            engine.config.PIECE_SQUARE_TABLES = pst
            wins = 0
            for _ in range(5):
                board = chess.Board()
                while not board.is_game_over():
                    move = engine.get_best_move(board, depth=4, difficulty='medium')
                    board.push(move)
                result = board.result()
                if result == '1-0' and board.turn == chess.BLACK or result == '0-1' and board.turn == chess.WHITE:
                    wins += 1
            engine.config.PIECE_VALUES = original_pv
            engine.config.PIECE_SQUARE_TABLES = original_pst
            return (wins / 5,)

        toolbox = base.Toolbox()
        toolbox.register("individual", generate_individual)
        toolbox.register("population", tools.initRepeat, list, toolbox.individual)
        toolbox.register("evaluate", evaluate_individual)
        toolbox.register("mate", tools.cxBlend, alpha=0.5)
        toolbox.register("mutate", tools.mutGaussian, mu=0, sigma=10, indpb=0.1)
        toolbox.register("select", tools.selTournament, tournsize=3)
        population = toolbox.population(n=population_size)
        for gen in range(generations):
            fitnesses = list(map(toolbox.evaluate, population))
            for ind, fit in zip(population, fitnesses):
                ind.fitness.values = fit
            population = toolbox.select(population, len(population))
            offspring = [toolbox.clone(ind) for ind in population]
            for child1, child2 in zip(offspring[::2], offspring[1::2]):
                if random.random() < 0.8:
                    toolbox.mate(child1, child2)
                    del child1.fitness.values
                    del child2.fitness.values
            for mutant in offspring:
                if random.random() < 0.2:
                    toolbox.mutate(mutant)
                    del mutant.fitness.values
            population = offspring
            logging.info(f"Feature engineering generation {gen + 1}/{generations} completed")
        best_ind = tools.selBest(population, 1)[0]
        idx = 0
        engine.config.PIECE_VALUES = {piece: best_ind[idx + i] for i, piece in enumerate(engine.config.PIECE_VALUES.keys())}
        engine.config.PIECE_SQUARE_TABLES = {}
        for piece in engine.config.PIECE_SQUARE_TABLES:
            engine.config.PIECE_SQUARE_TABLES[piece] = best_ind[idx:idx+64]
            idx += 64
        logging.info("Updated engine features with best candidate")

class ChessGUI:
    """Graphical interface for Shinigami using tkinter with ASCII pieces."""
    def __init__(self, engine):
        self.engine = engine
        self.board = chess.Board()
        self.root = tk.Tk()
        self.root.title("Shinigami Chess")
        self.canvas = tk.Canvas(self.root, width=400, height=400)
        self.canvas.pack()
        self.status = tk.Label(self.root, text="Select difficulty")
        self.status.pack()
        self.move_input = tk.Entry(self.root)
        self.move_input.pack()
        self.move_input.bind("<Return>", self.handle_move)
        self.ai_color = chess.BLACK
        self.difficulty = self.engine.select_difficulty()
        self.depth = self.engine.config.DEPTHS[self.difficulty]
        self.selected_square = None
        self.legal_moves = []
        self.canvas.bind("<Button-1>", self.handle_click)
        self.draw_board()

    def draw_board(self):
        """Draw the chessboard with ASCII pieces and move highlights."""
        self.canvas.delete("all")
        for i in range(8):
            for j in range(8):
                color = "white" if (i + j) % 2 == 0 else "gray"
                self.canvas.create_rectangle(j * 50, i * 50, (j + 1) * 50, (i + 1) * 50, fill=color)
                if (7 - i, j) in self.legal_moves:
                    self.canvas.create_oval(j * 50 + 10, i * 50 + 10, j * 50 + 40, i * 50 + 40, fill="yellow", stipple="gray50")
        for square in chess.SQUARES:
            piece = self.board.piece_at(square)
            if piece:
                self.canvas.create_text(
                    chess.square_file(square) * 50 + 25,
                    (7 - chess.square_rank(square)) * 50 + 25,
                    text=piece.symbol(),
                    font=("Courier", 24)
                )
        self.status.config(text=f"{'White' if self.board.turn == chess.WHITE else 'Black'} to move")
        if self.board.is_game_over():
            result = self.board.result()
            self.status.config(text=f"Game over: {result}")
        self.root.after(100, self.update)

    def handle_click(self, event):
        """Handle mouse clicks for move selection."""
        file = event.x // 50
        rank = 7 - (event.y // 50)
        square = chess.square(file, rank)
        if self.selected_square is None:
            if self.board.piece_at(square) and self.board.piece_at(square).color == self.board.turn:
                self.selected_square = square
                self.legal_moves = [move.to_square for move in self.board.legal_moves if move.from_square == square]
                self.draw_board()
        else:
            move = chess.Move(self.selected_square, square)
            if move in self.board.legal_moves:
                self.board.push(move)
                self.engine.training_module.learn_from_opponent(self.board, move, self.board.result() if self.board.is_game_over() else "ongoing")
                self.draw_board()
            self.selected_square = None
            self.legal_moves = []
            self.draw_board()

    def handle_move(self, event):
        """Handle text input for moves."""
        move_input = self.move_input.get().strip().lower()
        if move_input == "quit":
            self.root.quit()
        try:
            move = self.board.parse_san(move_input)
            if move in self.board.legal_moves:
                self.board.push(move)
                self.engine.training_module.learn_from_opponent(self.board, move, self.board.result() if self.board.is_game_over() else "ongoing")
                self.draw_board()
                self.move_input.delete(0, tk.END)
            else:
                self.status.config(text=random.choice(self.engine.config.TRASH_TALK["invalid"]))
        except ValueError:
            self.status.config(text=random.choice(self.engine.config.TRASH_TALK["invalid"]))

    def update(self):
        """Update board and handle AI moves."""
        if self.board.turn == self.ai_color and not self.board.is_game_over():
            move = self.engine.get_best_move(self.board, self.depth, self.difficulty)
            if move:
                self.board.push(move)
                self.draw_board()
                if self.board.is_check():
                    self.status.config(text=random.choice(self.engine.config.TRASH_TALK["check"]))
                elif self.board.is_capture(move):
                    self.status.config(text=random.choice(self.engine.config.TRASH_TALK["capture"]))
        self.root.after(100, self.update)

class ShinigamiEngine:
    """Main chess engine class with advanced evaluation and search."""
    def __init__(self):
        """Initialize the chess engine."""
        self.config = ShinigamiConfig()
        self.config.ENGINE_NAME = "Shinigami V.1.16.8 - Gen 2 Edition"  # Updated version
        self.tablebase = None
        try:
            self.tablebase = chess.syzygy.open_tablebase(self.config.SYZYGY_PATH)
            logging.info("Loaded Syzygy tablebase")
        except Exception as e:
            logging.warning(f"Failed to load Syzygy tablebase: {e}")
        self.opening_book = None
        try:
            self.opening_book = chess.polyglot.open_reader("book.bin")
            logging.info("Loaded Polyglot opening book")
        except Exception as e:
            logging.warning(f"Failed to load Polyglot opening book: {e}")
        self.tt_size = 2**20
        self.tt = mp.RawArray('Q', self.tt_size * 4)
        self.tt_lock = mp.Lock()
        self.pawn_tt = mp.RawArray('Q', 2**18 * 3)  # Pawn hash table (zobrist, score, flag)
        self.pawn_tt_lock = mp.Lock()
        self.eval_cache = mp.RawArray('Q', 2**18 * 2)  # Evaluation cache (zobrist, score)
        self.eval_cache_lock = mp.Lock()
        self.killer_moves = defaultdict(list)
        self.history_table = defaultdict(lambda: defaultdict(int))
        self.puzzle_database = [
            {"fen": "rnbqkb1r/pppp1ppp/5n2/4p3/4P3/5N2/PPPP1PPP/RNBQKB1R w KQkq - 0 1",
             "move": "Nf3", "task": "Find the best move to develop a piece."},
            {"fen": "rnbqkbnr/pppppppp/5n2/8/8/5N2/PPPPPPPP/RNBQKB1R w KQkq - 0 1",
             "move": "e4", "task": "Find the best opening move."},
            {"fen": "r1bqk2r/pppp1ppp/5n2/2b5/4P3/5N2/PPPP1PPP/RNBQKB1R w KQkq - 2 2",
             "move": "d4", "task": "Challenge the center with a pawn."},
            {"fen": "rnbqk2r/pppp1ppp/5n2/4p3/4P3/5N2/PPPP1PPP/RNBQKB1R w KQkq - 0 2",
             "move": "d4", "task": "Pin exploitation in the opening."}  # New puzzle
        ]
        self.nnue = AdvancedNNUEEvaluator(self.config.NNUE_FILE) if self.config.USE_NNUE else None
        self.training_module = TrainingModule()
        self.training_module.engine = self
        self.policy_network = PolicyNetwork() if self.config.USE_NNUE else None
        if self.config.USE_NNUE and self.policy_network:
            try:
                self.policy_network.load_state_dict(torch.load('policy_network.pth'))
                logging.info("Loaded policy network weights")
            except Exception as e:
                logging.warning(f"Failed to load policy network weights: {e}, training new model")
                self.training_module.train_policy_network(self.policy_network)
        self.nodes_searched = 0
        self.cutoffs = 0
        self.tt_hits = 0
        self.pawn_tt_hits = 0
        self.eval_cache_hits = 0
        self.stop_search = False
        self.ponder_move = None  # For pondering

    def evaluate_pawn_structure(self, board: chess.Board) -> int:
        """Evaluate pawn structure: isolated, doubled, passed, chains, islands."""
        score = 0
        white_pawns = board.pieces(chess.PAWN, chess.WHITE)
        black_pawns = board.pieces(chess.PAWN, chess.BLACK)
        files = [set() for _ in range(8)]
        for square in white_pawns:
            files[chess.square_file(square)].add(chess.square_rank(square))
        for square in black_pawns:
            files[chess.square_file(square)].add(chess.square_rank(square))
        # White pawns
        for square in white_pawns:
            file, rank = chess.square_file(square), chess.square_rank(square)
            # Isolated pawns
            if not (files[file-1] if file > 0 else set()) and not (files[file+1] if file < 7 else set()):
                score -= 20
            # Doubled pawns
            if len(files[file]) > 1:
                score -= 10 * (len(files[file]) - 1)
            # Passed pawns
            is_passed = True
            for f in range(max(0, file-1), min(8, file+2)):
                for r in range(rank+1, 8):
                    if chess.square(f, r) in black_pawns:
                        is_passed = False
                        break
                if not is_passed:
                    break
            if is_passed:
                score += 10 + (10 if rank >= 5 else 0)
            # Pawn chains
            for adj_file in (file-1, file+1):
                if 0 <= adj_file < 8 and rank+1 in files[adj_file]:
                    score += 5
        # Black pawns (mirrored)
        for square in black_pawns:
            file, rank = chess.square_file(square), 7 - chess.square_rank(square)
            if not (files[file-1] if file > 0 else set()) and not (files[file+1] if file < 7 else set()):
                score += 20
            if len(files[file]) > 1:
                score += 10 * (len(files[file]) - 1)
            is_passed = True
            for f in range(max(0, file-1), min(8, file+2)):
                for r in range(rank+1, 8):
                    if chess.square(f, 7-r) in white_pawns:
                        is_passed = False
                        break
                if not is_passed:
                    break
            if is_passed:
                score -= 10 + (10 if rank >= 5 else 0)
            for adj_file in (file-1, file+1):
                if 0 <= adj_file < 8 and rank+1 in files[adj_file]:
                    score -= 5
        # Pawn islands
        islands = 0
        in_island = False
        for f in range(8):
            if files[f]:
                if not in_island:
                    islands += 1
                    in_island = True
            else:
                in_island = False
        score -= 10 * islands  # Penalty for pawn islands
        return score

    def evaluate_king_safety(self, board: chess.Board) -> int:
        """Evaluate king safety: pawn shield, open files, attackers."""
        score = 0
        white_king = board.king(chess.WHITE)
        black_king = board.king(chess.BLACK)
        phase = self.get_game_phase(board)
        # White king safety
        if white_king is not None:
            king_file, king_rank = chess.square_file(white_king), chess.square_rank(white_king)
            shield_squares = [chess.square(f, r) for f in range(max(0, king_file-1), min(8, king_file+2))
                              for r in range(king_rank, min(8, king_rank+2)) if r >= king_rank]
            for square in shield_squares:
                if board.piece_at(square) and board.piece_at(square).piece_type == chess.PAWN and board.piece_at(square).color == chess.WHITE:
                    score += 15 * (1 - phase)  # More important in opening/middlegame
                else:
                    score -= 10 * (1 - phase)  # Missing shield pawn
            for f in range(max(0, king_file-1), min(8, king_file+2)):
                if not any(chess.square(f, r) in board.pieces(chess.PAWN, chess.WHITE) for r in range(8)):
                    score -= 10 * (1 - phase)  # Open file near king
            for square in board.attacks(white_king):
                if board.piece_at(square) and board.piece_at(square).color == chess.BLACK:
                    score -= self.config.PIECE_VALUES.get(board.piece_at(square).piece_type, 0) // 10 * (1 - phase)
        # Black king safety
        if black_king is not None:
            king_file, king_rank = chess.square_file(black_king), 7 - chess.square_rank(black_king)
            shield_squares = [chess.square(f, 7-r) for f in range(max(0, king_file-1), min(8, king_file+2))
                              for r in range(king_rank, min(8, king_rank+2)) if r >= king_rank]
            for square in shield_squares:
                if board.piece_at(square) and board.piece_at(square).piece_type == chess.PAWN and board.piece_at(square).color == chess.BLACK:
                    score -= 15 * (1 - phase)
                else:
                    score += 10 * (1 - phase)
            for f in range(max(0, king_file-1), min(8, king_file+2)):
                if not any(chess.square(f, 7-r) in board.pieces(chess.PAWN, chess.BLACK) for r in range(8)):
                    score += 10 * (1 - phase)
            for square in board.attacks(black_king):
                if board.piece_at(square) and board.piece_at(square).color == chess.WHITE:
                    score += self.config.PIECE_VALUES.get(board.piece_at(square).piece_type, 0) // 10 * (1 - phase)
        return score

    def get_game_phase(self, board: chess.Board) -> float:
        """Calculate game phase: 0 (endgame) to 1 (opening/middlegame)."""
        material = sum(self.config.PIECE_VALUES.get(p.piece_type, 0) for p in board.piece_map().values() if p.piece_type != chess.KING)
        max_material = 2 * (2 * self.config.PIECE_VALUES[chess.QUEEN] + 2 * self.config.PIECE_VALUES[chess.ROOK] +
                            2 * self.config.PIECE_VALUES[chess.BISHOP] + 2 * self.config.PIECE_VALUES[chess.KNIGHT])
        return min(1.0, max(0.0, material / max_material)) if max_material > 0 else 0.0

    def evaluate_position(self, board: chess.Board) -> int:
        """Evaluate the board position with advanced heuristics."""
        zobrist_hash = chess.polyglot.zobrist_hash(board)
        index = zobrist_hash % (2**18)
        with self.eval_cache_lock:
            if self.eval_cache[index * 2] == zobrist_hash:
                self.eval_cache_hits += 1
                return self.eval_cache[index * 2 + 1] - 2**31
        if self.tablebase and len(board.piece_map()) <= 7:
            try:
                wdl = self.tablebase.probe_wdl(board)
                dtz = self.tablebase.probe_dtz(board)
                score = wdl * 1000 if dtz >= 0 else -1000
                logging.info(f"Syzygy hit: WDL={wdl}, DTZ={dtz}, score={score}")
                with self.eval_cache_lock:
                    self.eval_cache[index * 2] = zobrist_hash
                    self.eval_cache[index * 2 + 1] = score + 2**31
                return score
            except:
                pass
        if self.config.USE_NNUE and self.nnue:
            score = self.nnue.evaluate(board)
            with self.eval_cache_lock:
                self.eval_cache[index * 2] = zobrist_hash
                self.eval_cache[index * 2 + 1] = score + 2**31
            return score
        score = 0
        phase = self.get_game_phase(board)
        # Material and PSTs
        for square in chess.SQUARES:
            piece = board.piece_at(square)
            if piece:
                value = self.config.PIECE_VALUES.get(piece.piece_type, 0)
                score += value * (1 if piece.color == chess.WHITE else -1)
                pst = self.config.PIECE_SQUARE_TABLES.get(piece.piece_type, [0] * 64)
                score += pst[square if piece.color == chess.WHITE else chess.square_mirror(square)] * (1 if piece.color == chess.WHITE else -1)
        # Pawn structure
        score += self.evaluate_pawn_structure(board)
        # King safety
        score += self.evaluate_king_safety(board)
        # Bishop pair
        if len(board.pieces(chess.BISHOP, chess.WHITE)) >= 2:
            score += 50 * phase
        if len(board.pieces(chess.BISHOP, chess.BLACK)) >= 2:
            score -= 50 * phase
        # Mobility
        for piece_type in [chess.KNIGHT, chess.BISHOP, chess.ROOK, chess.QUEEN]:
            for square in board.pieces(piece_type, chess.WHITE):
                score += len(board.attacks(square)) * 5 * phase
            for square in board.pieces(piece_type, chess.BLACK):
                score -= len(board.attacks(square)) * 5 * phase
        # Rook evaluation
        for square in board.pieces(chess.ROOK, chess.WHITE):
            file = chess.square_file(square)
            rank = chess.square_rank(square)
            if not board.pieces(chess.PAWN, chess.WHITE) & chess.BB_FILES[file]:
                score += 20 * phase  # Open file
            elif not board.pieces(chess.PAWN, chess.BLACK) & chess.BB_FILES[file]:
                score += 10 * phase  # Semi-open file
            if rank == 6:
                score += 30 * phase  # 7th rank
            # Connected rooks
            if len(board.pieces(chess.ROOK, chess.WHITE)) >= 2:
                score += 20 * phase
        for square in board.pieces(chess.ROOK, chess.BLACK):
            file = chess.square_file(square)
            rank = 7 - chess.square_rank(square)
            if not board.pieces(chess.PAWN, chess.BLACK) & chess.BB_FILES[file]:
                score -= 20 * phase
            elif not board.pieces(chess.PAWN, chess.WHITE) & chess.BB_FILES[file]:
                score -= 10 * phase
            if rank == 6:
                score -= 30 * phase
            if len(board.pieces(chess.ROOK, chess.BLACK)) >= 2:
                score -= 20 * phase
        # Outposts
        for piece_type in [chess.KNIGHT, chess.BISHOP]:
            for square in board.pieces(piece_type, chess.WHITE):
                file, rank = chess.square_file(square), chess.square_rank(square)
                if rank >= 3 and not any(chess.square(f, r) in board.pieces(chess.PAWN, chess.BLACK) for f in range(max(0, file-1), min(8, file+2)) for r in range(rank, 8)):
                    if any(chess.square(f, rank-1) in board.pieces(chess.PAWN, chess.WHITE) for f in (file-1, file+1) if 0 <= f < 8):
                        score += 25 * phase
            for square in board.pieces(piece_type, chess.BLACK):
                file, rank = chess.square_file(square), 7 - chess.square_rank(square)
                if rank >= 3 and not any(chess.square(f, 7-r) in board.pieces(chess.PAWN, chess.WHITE) for f in range(max(0, file-1), min(8, file+2)) for r in range(rank, 8)):
                    if any(chess.square(f, 7-(rank-1)) in board.pieces(chess.PAWN, chess.BLACK) for f in (file-1, file+1) if 0 <= f < 8):
                        score -= 25 * phase
        with self.eval_cache_lock:
            self.eval_cache[index * 2] = zobrist_hash
            self.eval_cache[index * 2 + 1] = score + 2**31
        return score

    def store_pawn_tt(self, zobrist_hash: int, score: int, flag: str):
        """Store pawn structure evaluation in pawn transposition table."""
        index = zobrist_hash % (2**18)
        with self.pawnefc36e6b2-3bc2-4e40-9a0c-a11a8cb5c3d0tt_lock:
            self.pawn_tt[index * 3] = zobrist_hash
            self.pawn_tt[index * 3 + 1] = score + 2**31
            self.pawn_tt[index * 3 + 2] = {'exact': 0, 'lower': 1, 'upper': 2}[flag]

    def probe_pawn_tt(self, zobrist_hash: int) -> tuple:
        """Probe pawn transposition table."""
        index = zobrist_hash % (2**18)
        with self.pawn_tt_lock:
            if self.pawn_tt[index * 3] == zobrist_hash:
                score = self.pawn_tt[index * 3 + 1] - 2**31
                flag = ['exact', 'lower', 'upper'][self.pawn_tt[index * 3 + 2]]
                self.pawn_tt_hits += 1
                return score, flag
        return None, None

    def see(self, board: chess.Board, move: chess.Move) -> int:
        """Static Exchange Evaluation for captures and threats."""
        target_square = move.to_square
        piece = board.piece_at(move.from_square)
        is_capture = board.is_capture(move)
        if not is_capture and piece:
            board.push(move)
            if board.is_check():
                board.pop()
                return 100
            attackers = board.attackers(not board.turn, target_square)
            pinned = any(board.is_pinned(not board.turn, sq) for sq in board.attackers(not board.turn, target_square))
            board.pop()
            if not attackers and not board.gives_check(move) and move.promotion is None:
                return 0
            return 80 if pinned else 50
        value = self.config.PIECE_VALUES.get(board.piece_at(target_square).piece_type, 0) if board.is_capture(move) else 0
        attackers = board.attackers(chess.WHITE, target_square) | board.attackers(chess.BLACK, target_square)
        if not attackers:
            return value
        piece_values = self.config.PIECE_VALUES
        board.push(move)
        gain = [value]
        us = board.turn
        them = not us
        attackers = board.attackers(them, target_square)
        while attackers:
            min_value = float('inf')
            min_piece = None
            for square in attackers:
                piece = board.piece_at(square)
                if piece and not board.is_pinned(them, square) and piece_values.get(piece.piece_type, 0) < min_value:
                    min_value = piece_values.get(piece.piece_type, 0)
                    min_piece = square
            if min_piece is None:
                break
            next_move = chess.Move(min_piece, target_square)
            if next_move not in board.legal_moves:
                break
            board.push(next_move)
            gain.append(piece_values.get(board.piece_at(target_square).piece_type, 0) if board.piece_at(target_square) else 0)
            us, them = them, us
            attackers = board.attackers(them, target_square)
        while len(board.move_stack) > 1:
            board.pop()
        board.pop()
        result = gain[0]
        for i in range(1, len(gain), 2):
            result -= gain[i]
            if i + 1 < len(gain):
                result = max(0, result + gain[i + 1])
        return result

    def quiescence(self, board: chess.Board, alpha: int, beta: int, depth_limit: int) -> int:
        """Quiescence search with delta pruning and SEE-based move ordering."""
        if self.stop_search:
            return alpha
        self.nodes_searched += 1
        if depth_limit <= 0 or board.is_game_over():
            return self.evaluate_position(board)
        stand_pat = self.evaluate_position(board)
        if stand_pat >= beta:
            self.cutoffs += 1
            return beta
        big_delta = self.config.PIECE_VALUES[chess.QUEEN] + 100  # Max material gain + margin
        if stand_pat < alpha - big_delta:
            return alpha
        alpha = max(alpha, stand_pat)
        move_scores = []
        for move in board.legal_moves:
            if board.is_capture(move) or board.gives_check(move) or move.promotion:
                score = self.see(board, move)
                move_scores.append((move, score))
            elif self.is_threatening_move(board, move):
                move_scores.append((move, 50))
        move_scores.sort(key=lambda x: x[1], reverse=True)
        for move, _ in move_scores:
            board.push(move)
            score = -self.quiescence(board, -beta, -alpha, depth_limit - 1)
            board.pop()
            if score >= beta:
                self.cutoffs += 1
                return beta
            alpha = max(alpha, score)
        return alpha

    def is_threatening_move(self, board: chess.Board, move: chess.Move) -> bool:
        """Check if a move creates a significant threat."""
        board.push(move)
        attackers = set()
        for square in chess.SQUARES:
            piece = board.piece_at(square)
            if piece and piece.color == board.turn:
                for target in board.attacks(square):
                    if board.piece_at(target) and board.piece_at(target).color != board.turn:
                        attackers.add(target)
        board.pop()
        return len(attackers) > 0 or board.gives_check(move)

    def store_tt(self, zobrist_hash, move, score, depth, flag):
        """Store entry in transposition table."""
        index = zobrist_hash % self.tt_size
        with self.tt_lock:
            self.tt[index * 4] = zobrist_hash
            self.tt[index * 4 + 1] = move.to_square | (move.from_square << 6) | (move.promotion << 12 if move.promotion else 0)
            self.tt[index * 4 + 2] = score + 2**31
            self.tt[index * 4 + 3] = (depth << 2) | {'exact': 0, 'lower': 1, 'upper': 2}[flag]

    def probe_tt(self, zobrist_hash, depth):
        """Probe transposition table for entry."""
        index = zobrist_hash % self.tt_size
        with self.tt_lock:
            if self.tt[index * 4] == zobrist_hash and self.tt[index * 4 + 3] >> 2 >= depth:
                score = self.tt[index * 4 + 2] - 2**31
                move_data = self.tt[index * 4 + 1]
                from_square = move_data >> 6 & 63
                to_square = move_data & 63
                promotion = (move_data >> 12) if move_data >> 12 in [chess.QUEEN, chess.ROOK, chess.BISHOP, chess.KNIGHT] else None
                move = chess.Move(from_square, to_square, promotion)
                flag = ['exact', 'lower', 'upper'][self.tt[index * 4 + 3] & 3]
                self.tt_hits += 1
                return {'move': move, 'score': score, 'depth': self.tt[index * 4 + 3] >> 2, 'flag': flag}
        return None

    def alpha_beta(self, board: chess.Board, depth: int, alpha: int, beta: int, maximizing_player: bool, null_move=True) -> tuple:
        """Alpha-beta pruning with extensions, PVS, null move, LMR, and SEE ordering."""
        if self.stop_search:
            return None, alpha
        self.nodes_searched += 1
        zobrist_hash = chess.polyglot.zobrist_hash(board)
        tt_entry = self.probe_tt(zobrist_hash, depth)
        if tt_entry and tt_entry['depth'] >= depth:
            if tt_entry['flag'] == 'exact':
                return tt_entry['move'], tt_entry['score']
            elif tt_entry['flag'] == 'lower' and tt_entry['score'] >= beta:
                return tt_entry['move'], tt_entry['score']
            elif tt_entry['flag'] == 'upper' and tt_entry['score'] <= alpha:
                return tt_entry['move'], tt_entry['score']
        if depth <= 0 or board.is_game_over():
            return None, self.quiescence(board, alpha, beta, 6)
        # Extensions
        extension = 0
        if board.is_check():
            extension += 1
        if board.is_capture(board.move_stack[-1] if board.move_stack else None):  # Recapture extension
            extension += 1
        if any(move.promotion and move.to_square in chess.BB_RANKS[6:8] for move in board.legal_moves):  # Passed pawn push
            extension += 1
        if any(board.push(move) and board.is_checkmate() for move in board.legal_moves):  # One-move mate threat
            board.pop()
            extension += 1
        depth += extension
        # Null move pruning
        if null_move and depth >= 3 and not board.is_check() and not board.is_game_over():
            board.push(chess.Move.null())
            _, score = self.alpha_beta(board, depth - 3, -beta, -beta + 1, not maximizing_player, False)
            board.pop()
            if -score >= beta:
                self.cutoffs += 1
                return None, beta
        # Futility pruning
        futility_margin = 150 if depth == 1 else 300 if depth == 2 else float('inf')
        if depth <= 2 and not board.is_check() and not any(board.is_capture(m) or board.gives_check(m) for m in board.legal_moves):
            eval_score = self.evaluate_position(board)
            if eval_score + futility_margin <= alpha:
                return None, alpha
        # Internal Iterative Deepening
        tt_move = tt_entry['move'] if tt_entry else None
        if not tt_move and depth >= 3:
            _, _ = self.alpha_beta(board, depth - 2, alpha, beta, maximizing_player, False)
            tt_entry = self.probe_tt(zobrist_hash, depth - 2)
            tt_move = tt_entry['move'] if tt_entry else None
        # Move ordering
        move_scores = []
        killers = self.killer_moves.get(depth, [])
        legal_moves = list(board.legal_moves)
        if self.policy_network and self.config.USE_NNUE:
            move_probs = self.policy_network.get_move_probabilities(board, legal_moves)
            for move in legal_moves:
                score = move_probs.get(move, 0.0) * 10000
                if move == tt_move:
                    score += 20000
                if move in killers:
                    score += 10000
                score += self.history_table[zobrist_hash].get(move.uci(), 0)
                score += self.see(board, move)
                move_scores.append((move, score))
        else:
            for move in legal_moves:
                score = 0
                if move == tt_move:
                    score += 20000
                if move in killers:
                    score += 10000
                score += self.history_table[zobrist_hash].get(move.uci(), 0)
                score += self.see(board, move)
                move_scores.append((move, score))
        move_scores.sort(key=lambda x: x[1], reverse=True)
        ordered_moves = [move for move, _ in move_scores]
        best_move = None
        if maximizing_player:
            value = -float('inf')
            for idx, move in enumerate(ordered_moves):
                board.push(move)
                if idx == 0:
                    _, score = self.alpha_beta(board, depth - 1, alpha, beta, False)
                else:
                    reduction = 1 if idx >= 4 and depth >= 3 and not board.is_check() and not board.is_capture(move) else 0
                    _, score = self.alpha_beta(board, depth - 1 - reduction, alpha, alpha + 1, False)
                    if alpha < score < beta and reduction > 0:
                        _, score = self.alpha_beta(board, depth - 1, alpha, beta, False)
                board.pop()
                if score > value:
                    value = score
                    best_move = move
                alpha = max(alpha, value)
                if alpha >= beta:
                    self.cutoffs += 1
                    if not board.is_capture(move):
                        self.killer_moves[depth].append(move)
                        if len(self.killer_moves[depth]) > 2:
                            self.killer_moves[depth].pop(0)
                        self.history_table[zobrist_hash][move.uci()] += depth * depth
                    self.store_tt(zobrist_hash, best_move, value, depth, 'exact' if value <= alpha or value >= beta else 'lower')
                    break
            self.store_tt(zobrist_hash, best_move, value, depth, 'exact' if value <= alpha or value >= beta else 'lower')
        else:
            value = float('inf')
            for idx, move in enumerate(ordered_moves):
                board.push(move)
                if idx == 0:
                    _, score = self.alpha_beta(board, depth - 1, alpha, beta, True)
                else:
                    reduction = 1 if idx >= 4 and depth >= 3 and not board.is_check() and not board.is_capture(move) else 0
                    _, score = self.alpha_beta(board, depth - 1 - reduction, alpha, alpha + 1, True)
                    if alpha < score < beta and reduction > 0:
                        _, score = self.alpha_beta(board, depth - 1, alpha, beta, True)
                board.pop()
                if score < value:
                    value = score
                    best_move = move
                beta = min(beta, value)
                if alpha >= beta:
                    self.cutoffs += 1
                    if not board.is_capture(move):
                        self.killer_moves[depth].append(move)
                        if len(self.killer_moves[depth]) > 2:
                            self.killer_moves[depth].pop(0)
                        self.history_table[zobrist_hash][move.uci()] += depth * depth
                    self.store_tt(zobrist_hash, best_move, value, depth, 'exact' if value <= alpha or value >= beta else 'upper')
                    break
            self.store_tt(zobrist_hash, best_move, value, depth, 'exact' if value <= alpha or value >= beta else 'upper')
        return best_move, value

    def iterative_deepening(self, board: chess.Board, depth: int, time_control: dict) -> tuple:
        """Iterative deepening search with aspiration windows, dynamic time allocation, and pondering."""
        start_time = time.time()
        time_limit = time_control['base']
        increment = time_control.get('increment', 0)
        if increment:
            time_limit += increment * (board.fullmove_number - 1)
        legal_moves = list(board.legal_moves)
        complexity = len(legal_moves) + (10 if board.is_check() else 0)
        time_limit = min(time_limit, time_limit * (1 + complexity / 50))  # Dynamic time allocation
        overtime_limit = time_limit * 1.1  # Allow 10% overtime for critical moves
        best_move = None
        best_score = 0
        prev_score = 0
        window = 50  # Initial aspiration window
        current_depth = 1
        self.nodes_searched = 0
        self.cutoffs = 0
        self.tt_hits = 0
        self.pawn_tt_hits = 0
        self.eval_cache_hits = 0
        profiler = cProfile.Profile()
        profiler.enable()
        if not legal_moves:
            return None, 0

        # Pondering setup: predict opponent's most likely move
        if self.ponder_move and self.ponder_move in legal_moves:
            board.push(self.ponder_move)
            _, ponder_score = self.alpha_beta(board, depth - 1, -float('inf'), float('inf'), not board.turn)
            board.pop()
            logging.info(f"Pondered on move {self.ponder_move.uci()}, score: {ponder_score}")

        while current_depth <= depth and time.time() - start_time < time_limit and not self.stop_search:
            alpha = prev_score - window if best_move else -float('inf')
            beta = prev_score + window if best_move else float('inf')
            try:
                temp_move, score = self.alpha_beta(board, current_depth, alpha, beta, board.turn == chess.WHITE)
                if score <= alpha or score >= beta:  # Aspiration window fail, re-search
                    alpha = -float('inf')
                    beta = float('inf')
                    temp_move, score = self.alpha_beta(board, current_depth, alpha, beta, board.turn == chess.WHITE)
                best_move = temp_move
                best_score = score
                prev_score = score
                window = max(25, window * 0.75)  # Shrink window for next iteration
                logging.debug(f"Depth {current_depth}: Best move {best_move.uci() if best_move else 'None'}, score {score}")
            except Exception as e:
                logging.error(f"Search error at depth {current_depth}: {e}")
                break
            current_depth += 1
            # Allow slight overtime if close to a better move
            if time.time() - start_time > time_limit and (time.time() - start_time < overtime_limit or score > prev_score + 100):
                continue
            if time.time() - start_time >= overtime_limit:
                break

        # Set up pondering for next move
        if best_move:
            board_copy = board.copy()
            board_copy.push(best_move)
            move_probs = self.policy_network.get_move_probabilities(board_copy, list(board_copy.legal_moves)) if self.policy_network else {}
            self.ponder_move = max(move_probs.items(), key=lambda x: x[1], default=(None, 0))[0] if move_probs else None

        profiler.disable()
        stats = pstats.Stats(profiler).sort_stats('cumulative')
        stats.dump_stats('shinigami_profile.prof')
        logging.info(f"Nodes searched: {self.nodes_searched}, Cutoffs: {self.cutoffs}, TT hits: {self.tt_hits}, "
                     f"Pawn TT hits: {self.pawn_tt_hits}, Eval cache hits: {self.eval_cache_hits}")
        return best_move, best_score

    def search_chunk(self, board: chess.Board, depth: int, moves: list, alpha: int, beta: int, maximizing_player: bool) -> list:
        """Search a chunk of moves in parallel."""
        results = []
        for move in moves:
            if self.stop_search:
                break
            board.push(move)
            _, score = self.alpha_beta(board, depth - 1, alpha, beta, not maximizing_player)
            board.pop()
            results.append((move, score))
            if maximizing_player and score >= beta or not maximizing_player and score <= alpha:
                break
        return results

    def get_best_move(self, board: chess.Board, depth: int, difficulty: str) -> chess.Move:
        """Get the best move for the given board position."""
        time_control = self.config.TIME_CONTROLS.get(difficulty, self.config.TIME_CONTROLS['medium'])
        depth = self.config.DEPTHS.get(difficulty, depth)
        if difficulty == 'the-big-bang':
            logging.warning(random.choice(self.config.TRASH_TALK['the_big_bang']))
            depth = 10  # Fallback to sane depth
        if depth > 100:
            logging.warning("Depth too high! Reducing to 10 to avoid eternal suffering.")
            depth = 10
        if self.opening_book:
            try:
                entries = list(self.opening_book.find_all(board))
                if entries:
                    weights = [entry.weight for entry in entries]
                    best_entry = random.choices(entries, weights=weights, k=1)[0]
                    move = best_entry.move
                    logging.info(f"Opening book move: {move.uci()}")
                    return move
            except Exception as e:
                logging.warning(f"Opening book error: {e}")
        move, score = self.iterative_deepening(board, depth, time_control)
        if move:
            logging.info(f"Best move: {move.uci()}, Score: {score}")
            if board.is_check():
                logging.info(random.choice(self.config.TRASH_TALK['check']))
            elif board.is_capture(move):
                logging.info(random.choice(self.config.TRASH_TALK['capture']))
            self.training_module.learn_from_opponent(board, move, "ongoing")
        else:
            logging.warning("No move found, likely game over or illegal position")
        return move

    def get_opening_move(self, board: chess.Board) -> chess.Move:
        """Get move from Polyglot or dynamic opening book."""
        if self.opening_book:
            try:
                entry = self.opening_book.weighted_choice(board)
                logging.info(f"Polyglot book move: {entry.move.uci()}")
                return entry.move
            except:
                pass
        zobrist_hash = chess.polyglot.zobrist_hash(board)
        if zobrist_hash in self.training_module.opening_book:
            moves = []
            weights = []
            for move in board.legal_moves:
                board_copy = board.copy()
                board_copy.push(move)
                move_hash = chess.polyglot.zobrist_hash(board_copy)
                if move_hash in self.training_module.opening_book:
                    moves.append(move)
                    weights.append(self.training_module.opening_book[move_hash]['weight'])
            if moves:
                move = random.choices(moves, weights=weights, k=1)[0]
                logging.info(f"Dynamic book move: {move.uci()}")
                return move
        return None

    def generate_puzzle(self, board: chess.Board) -> tuple:
        """Generate a puzzle from the puzzle database."""
        if self.puzzle_database:
            puzzle = random.choice(self.puzzle_database)
            board.set_fen(puzzle['fen'])
            try:
                move = board.parse_san(puzzle['move'])
                logging.info(f"Generated puzzle: {puzzle['task']}, move: {move.uci()}")
                return move, puzzle['task']
            except ValueError:
                logging.warning(f"Invalid puzzle move: {puzzle['move']}")
        return None, None

    def select_difficulty(self) -> str:
        """Select AI difficulty with confirmation for extreme modes and safeguard for The Big Bang."""
        print("Select AI difficulty: 1) Easy, 2) Medium, 3) Hard, 4) God-Of-Death, 5) Puzzle Mode, 6) Masochist, 7) Dialing Satan's Number, 8) The Big Bang")
        while True:
            difficulty_input = input("Enter 1, 2, 3, 4, 5, 6, 7, or 8: ").strip()
            difficulties = {
                '1': 'easy',
                '2': 'medium',
                '3': 'hard',
                '4': 'god-of-death',
                '5': 'puzzle',
                '6': 'masochist',
                '7': 'dialing-satan-s-number',
                '8': 'the-big-bang'
            }
            if difficulty_input in difficulties:
                difficulty = difficulties[difficulty_input]
                if difficulty == 'the-big-bang':
                    print(random.choice(self.config.TRASH_TALK["the_big_bang"]))
                    logging.warning("Attempted to enable The Big Bang mode; rejected due to safeguard")
                    continue
                if difficulty in ['masochist', 'dialing-satan-s-number']:
                    for i in range(3):
                        confirm = input(f"Confirm enabling {difficulty} (step {i+1}/3) [y/n]: ").strip().lower()
                        if confirm != 'y':
                            print(f"Extreme mode {difficulty} cancelled.")
                            break
                    else:
                        print(f"Warning: {difficulty} enabled. Good luck!")
                        return difficulty
                return difficulty
            print("Invalid input. Try again.")

    def play_chess_with_ai(self, ai_color: chess.Color):
        """Main game loop for human vs. AI play in console mode."""
        board = chess.Board()
        difficulty = self.select_difficulty()
        depth = self.config.DEPTHS[difficulty]
        print(f"NNUE: {'Enabled' if self.config.USE_NNUE else 'Disabled'}")
        print(f"Syzygy Tablebases: {'Loaded' if self.tablebase else 'Not Loaded'}")
        print(f"Opening Book: {'Loaded' if self.opening_book else 'Not Loaded'}")
        logging.info(f"Game started: AI as {'Black' if ai_color == chess.BLACK else 'White'}, Difficulty: {difficulty}")
        while not board.is_game_over():
            print(f"\n{board}\n")
            player = "White" if board.turn == chess.WHITE else "Black"
            print(f"{player}'s turn. Don't bore me.")
            if difficulty == "puzzle":
                puzzle_move, puzzle_task = self.generate_puzzle(board)
                if puzzle_move:
                    print(f"Puzzle Mode: {puzzle_task}\n")
                    while True:
                        move_input = input("Your move (or 'retry'/'exit'): ").strip().lower()
                        if move_input == "exit":
                            logging.info("Player exited puzzle mode")
                            return
                        elif move_input == "retry":
                            continue
                        try:
                            move = board.parse_san(move_input)
                            if move == puzzle_move:
                                print("Puzzle solved! Want another? (y/n)")
                                logging.info("Puzzle solved correctly")
                                if input().strip().lower() == 'y':
                                    board = chess.Board()
                                    puzzle_move, puzzle_task = self.generate_puzzle(board)
                                    if not puzzle_move:
                                        print("No more puzzles available. Switching to medium mode.")
                                        difficulty = "medium"
                                        depth = self.config.DEPTHS["medium"]
                                        break
                                    print(f"\nNew Puzzle: {puzzle_task}\n")
                                else:
                                    return
                            else:
                                print("Wrong move! Try again or 'retry'.")
                                logging.warning(f"Incorrect puzzle move: {move_input}")
                        except ValueError:
                            print(random.choice(self.config.TRASH_TALK["invalid"]))
                            continue
            elif board.turn == ai_color:
                print("Shinigami is plotting your demise...")
                move = self.get_best_move(board, depth, difficulty)
                if move:
                    board.push(move)
                    logging.info(f"AI move: {move.uci()}")
                    if board.is_check():
                        print(random.choice(self.config.TRASH_TALK["check"]))
                    elif board.is_capture(move):
                        print(random.choice(self.config.TRASH_TALK["capture"]))
            else:
                move_input = input("Your move: ").strip().lower()
                if move_input == "quit":
                    break
                try:
                    move = board.parse_san(move_input)
                    board.push(move)
                    self.training_module.learn_from_opponent(board, move, board.result() if board.is_game_over() else "ongoing")
                except ValueError:
                    print(random.choice(self.config.TRASH_TALK["invalid"]))
                    logging.warning(f"Invalid move input: {move_input}")
        result = board.result()
        if result == "1-0":
            print(random.choice(self.config.TRASH_TALK["loss"]))
            logging.info("Game ended: White wins")
        elif result == "0-1":
            print(random.choice(self.config.TRASH_TALK["win"]))
            logging.info("Game ended: Black wins")
        else:
            print(random.choice(self.config.TRASH_TALK["draw"]))
            logging.info("Game ended: Draw")

    def uci_loop(self):
        """Handle UCI protocol commands for integration with chess GUIs."""
        manager = Manager()
        self.stop_search = manager.Value('b', False)
        board = chess.Board()
        while True:
            command = input().strip()
            if command == "uci":
                print(f"id name {self.config.ENGINE_NAME}")
                print("id author Tonmoy-KS")
                print("option name UseNNUE type check default true")
                print("uciok")
            elif command == "isready":
                print("readyok")
            elif command.startswith("setoption name UseNNUE"):
                self.config.USE_NNUE = "value true" in command.lower()
                print(f"info string NNUE {'enabled' if self.config.USE_NNUE else 'disabled'}")
            elif command == "stop":
                self.stop_search.value = True
            elif command.startswith("position"):
                parts = command.split()
                board = chess.Board()
                if parts[1] == "startpos" and "moves" in parts:
                    moves = parts[parts.index("moves") + 1:]
                    for move in moves:
                        board.push_uci(move)
            elif command.startswith("go"):
                parts = command.split()
                difficulty = "hard"
                depth = self.config.DEPTHS[difficulty]
                time_control = self.config.TIME_CONTROLS[difficulty].copy()
                if "wtime" in parts and "btime" in parts:
                    time_control['base'] = int(parts[parts.index("wtime") + 1]) / 1000 if board.turn == chess.WHITE else int(parts[parts.index("btime") + 1]) / 1000
                    time_control['increment'] = int(parts[parts.index("winc") + 1]) / 1000 if "winc" in parts else 0
                elif "movetime" in parts:
                    time_control['base'] = int(parts[parts.index("movetime") + 1]) / 1000
                    time_control['increment'] = 0
                self.stop_search.value = False
                move = self.iterative_deepening(board, depth, time_control)[0]
                if move:
                    print(f"bestmove {move.uci()}")
            elif command == "quit":
                break

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description="Shinigami Chess Engine")
    parser.add_argument('--cores', type=int, default=ShinigamiConfig.NUM_PROCESSES, help="Number of CPU cores to use")
    parser.add_argument('--gui', action='store_true', help="Run with GUI")
    parser.add_argument('--self-play', type=int, default=0, help="Run self-play for specified number of games")
    parser.add_argument('--nnue-file', type=str, default=ShinigamiConfig.NNUE_FILE, help="Path to NNUE weights file")
    parser.add_argument('--syzygy-path', type=str, default=ShinigamiConfig.SYZYGY_PATH, help="Path to Syzygy tablebases")
    args = parser.parse_args()
    ShinigamiConfig.NUM_PROCESSES = min(max(1, args.cores), mp.cpu_count())
    ShinigamiConfig.NNUE_FILE = args.nnue_file
    ShinigamiConfig.SYZYGY_PATH = args.syzygy_path
    mp.set_start_method('spawn' if os.name == 'nt' else 'fork')
    engine = ShinigamiEngine()
    if args.self_play > 0:
        engine.training_module.self_play(engine, args.self_play)
        engine.training_module.retrain_nnue()
        engine.training_module.train_policy_network(engine.policy_network)
    elif args.gui:
        gui = ChessGUI(engine)
        gui.root.mainloop()
    else:
        engine.play_chess_with_ai(chess.BLACK)
